package shell

import (
	"crypto/sha256"
	"fmt"
	"io"
	"os"
	"os/exec"
	"path/filepath"
	"sort"
	"strings"
	"sync"

	"github.com/spf13/cobra"
)

func getInitCommand() *cobra.Command {
	var force bool

	cmd := &cobra.Command{
		Use:   "init [shell]",
		Short: "Generate shell initialization script",
		Long: `Generates shell initialization by concatenating prelude scripts.
Uses caching for performance - regenerates only when source files change.`,
		Args: cobra.MaximumNArgs(1),
		RunE: func(cmd *cobra.Command, args []string) error {
			shell := "bash"
			if len(args) > 0 {
				shell = args[0]
			}

			// Find dotfiles root
			dotfilesRoot, err := findDotfilesRoot()
			if err != nil {
				return fmt.Errorf("failed to find dotfiles root: %w", err)
			}

			preludeDir := filepath.Join(dotfilesRoot, "bin", "prelude")

			// Get cache path
			cacheDir := getCacheDir()
			if err := os.MkdirAll(cacheDir, 0755); err != nil {
				return fmt.Errorf("failed to create cache directory: %w", err)
			}

			cacheFile := filepath.Join(cacheDir, fmt.Sprintf("shell-init-%s.bash", shell))
			hashFile := filepath.Join(cacheDir, fmt.Sprintf("shell-init-%s.hash", shell))

			// Read all prelude files in parallel
			allFiles, err := filepath.Glob(filepath.Join(preludeDir, "*.sh"))
			if err != nil {
				return fmt.Errorf("failed to list prelude files: %w", err)
			}

			// Separate .source.sh files from regular .sh files
			var files []string
			sourceFiles := make(map[string]string) // basename -> path

			for _, file := range allFiles {
				basename := filepath.Base(file)
				if strings.HasSuffix(basename, ".source.sh") {
					// Map the base name without .source.sh extension
					key := strings.TrimSuffix(basename, ".source.sh")
					sourceFiles[key] = file
				} else {
					files = append(files, file)
				}
			}
			sort.Strings(files)

			// Calculate hash of all files
			currentHash, err := calculateFilesHash(files)
			if err != nil {
				return fmt.Errorf("failed to calculate hash: %w", err)
			}

			// Check if cache is valid
			if !force {
				if cachedHash, err := os.ReadFile(hashFile); err == nil {
					if string(cachedHash) == currentHash {
						// Cache is valid, return cached content
						content, err := os.ReadFile(cacheFile)
						if err == nil {
							fmt.Print(string(content))
							return nil
						}
					}
				}
			}

			// Read all files in parallel
			type fileContent struct {
				path    string
				content string
				err     error
			}

			results := make(chan fileContent, len(files))
			var wg sync.WaitGroup

			for _, file := range files {
				wg.Add(1)
				go func(path string) {
					defer wg.Done()
					content, err := os.ReadFile(path)
					results <- fileContent{
						path:    path,
						content: string(content),
						err:     err,
					}
				}(file)
			}

			// Wait and close results channel
			go func() {
				wg.Wait()
				close(results)
			}()

			// Collect results maintaining order
			contentMap := make(map[string]string)
			for result := range results {
				if result.err != nil {
					return fmt.Errorf("failed to read %s: %w", result.path, result.err)
				}
				contentMap[result.path] = result.content
			}

			// Execute .source.sh files in parallel
			sourceOutputs, err := executeSourceFiles(sourceFiles)
			if err != nil {
				return fmt.Errorf("failed to execute source files: %w", err)
			}

			// Build output in order
			var output strings.Builder
			output.WriteString("# Generated by workspaced shell init\n")
			output.WriteString("# This file is cached for performance\n")
			output.WriteString("# Commands executed in parallel for faster loading\n\n")
			output.WriteString("# Flag to indicate workspaced shell init is being used\n")
			output.WriteString("export WORKSPACED_SHELL_INIT=1\n\n")

			for _, file := range files {
				basename := filepath.Base(file)
				baseKey := strings.TrimSuffix(basename, ".sh")

				// Check if there's a .source.sh file - if so, use ONLY its output
				if sourceOutput, hasSource := sourceOutputs[baseKey]; hasSource {
					output.WriteString(fmt.Sprintf("# Source: %s (generated by %s.source.sh)\n", basename, baseKey))
					output.WriteString(sourceOutput)
					if !strings.HasSuffix(sourceOutput, "\n") {
						output.WriteString("\n")
					}
					output.WriteString("\n")
					continue
				}

				// Regular file processing
				content := contentMap[file]
				output.WriteString(fmt.Sprintf("# Source: %s\n", basename))
				output.WriteString(content)

				if !strings.HasSuffix(content, "\n") {
					output.WriteString("\n")
				}
				output.WriteString("\n")
			}

			result := output.String()

			// Save to cache
			if err := os.WriteFile(cacheFile, []byte(result), 0644); err != nil {
				// Non-fatal, continue
				fmt.Fprintf(os.Stderr, "Warning: failed to write cache: %v\n", err)
			}
			if err := os.WriteFile(hashFile, []byte(currentHash), 0644); err != nil {
				// Non-fatal, continue
				fmt.Fprintf(os.Stderr, "Warning: failed to write hash: %v\n", err)
			}

			fmt.Print(result)
			return nil
		},
	}

	cmd.Flags().BoolVarP(&force, "force", "f", false, "Force regeneration, ignore cache")

	return cmd
}

func findDotfilesRoot() (string, error) {
	// Try common locations
	home := os.Getenv("HOME")
	locations := []string{
		filepath.Join(home, ".dotfiles"),
		"/etc/.dotfiles",
	}

	for _, loc := range locations {
		if info, err := os.Stat(filepath.Join(loc, "bin", "prelude")); err == nil && info.IsDir() {
			return loc, nil
		}
	}

	return "", fmt.Errorf("dotfiles root not found")
}

func getCacheDir() string {
	if xdgCache := os.Getenv("XDG_CACHE_HOME"); xdgCache != "" {
		return filepath.Join(xdgCache, "workspaced")
	}
	return filepath.Join(os.Getenv("HOME"), ".cache", "workspaced")
}

func calculateFilesHash(files []string) (string, error) {
	h := sha256.New()

	for _, file := range files {
		// Include filename in hash
		if _, err := h.Write([]byte(file)); err != nil {
			return "", err
		}

		// Include file content
		f, err := os.Open(file)
		if err != nil {
			return "", err
		}
		if _, err := io.Copy(h, f); err != nil {
			f.Close()
			return "", err
		}
		f.Close()
	}

	return fmt.Sprintf("%x", h.Sum(nil)), nil
}

// executeSourceFiles executes all .source.sh files in parallel and returns their outputs
func executeSourceFiles(sourceFiles map[string]string) (map[string]string, error) {
	if len(sourceFiles) == 0 {
		return make(map[string]string), nil
	}

	type sourceResult struct {
		key    string
		output string
		err    error
	}

	results := make(chan sourceResult, len(sourceFiles))
	var wg sync.WaitGroup

	for key, path := range sourceFiles {
		wg.Add(1)
		go func(k, p string) {
			defer wg.Done()

			// Execute the source file with bash
			cmd := exec.Command("bash", p)
			cmd.Env = os.Environ()
			output, err := cmd.Output()

			results <- sourceResult{
				key:    k,
				output: string(output),
				err:    err,
			}
		}(key, path)
	}

	go func() {
		wg.Wait()
		close(results)
	}()

	// Collect results
	outputMap := make(map[string]string)
	for result := range results {
		if result.err != nil {
			// Log warning but don't fail - just skip this source file
			fmt.Fprintf(os.Stderr, "Warning: failed to execute %s.source.sh: %v\n", result.key, result.err)
			continue
		}
		outputMap[result.key] = result.output
	}

	return outputMap, nil
}

// Patterns to detect shell command invocations
var commandPatterns = []*regexp.Regexp{
	// eval "$(command args)"
	regexp.MustCompile(`eval\s+"?\$\(([^)]+)\)"?`),
	// source <(command args)
	regexp.MustCompile(`source\s+<\(([^)]+)\)`),
	// . <(command args)
	regexp.MustCompile(`\.\s+<\(([^)]+)\)`),
}

type commandExecution struct {
	cmd    string
	output string
	err    error
}

// executeCommandsInParallel finds all command invocations and executes them in parallel
func executeCommandsInParallel(contentMap map[string]string) (map[string]string, error) {
	// Collect unique commands
	commandSet := make(map[string]bool)
	for _, content := range contentMap {
		for _, pattern := range commandPatterns {
			matches := pattern.FindAllStringSubmatch(content, -1)
			for _, match := range matches {
				if len(match) > 1 {
					cmd := strings.TrimSpace(match[1])
					commandSet[cmd] = true
				}
			}
		}
	}

	if len(commandSet) == 0 {
		return make(map[string]string), nil
	}

	// Execute all commands in parallel
	results := make(chan commandExecution, len(commandSet))
	var wg sync.WaitGroup

	for cmd := range commandSet {
		wg.Add(1)
		go func(command string) {
			defer wg.Done()

			// Skip if command doesn't exist
			cmdParts := strings.Fields(command)
			if len(cmdParts) == 0 {
				results <- commandExecution{cmd: command, output: "", err: nil}
				return
			}

			// Check if command exists
			if _, err := exec.LookPath(cmdParts[0]); err != nil {
				// Command doesn't exist, keep original
				results <- commandExecution{cmd: command, output: "", err: err}
				return
			}

			// Execute command
			bashCmd := exec.Command("bash", "-c", command)
			bashCmd.Env = os.Environ()
			output, err := bashCmd.Output()

			results <- commandExecution{
				cmd:    command,
				output: string(output),
				err:    err,
			}
		}(cmd)
	}

	// Wait and close
	go func() {
		wg.Wait()
		close(results)
	}()

	// Collect results
	commandMap := make(map[string]string)
	for result := range results {
		if result.err == nil && result.output != "" {
			commandMap[result.cmd] = result.output
		}
	}

	return commandMap, nil
}

// replaceSourceCommands replaces source/eval commands with the cached output from .source.sh
func replaceSourceCommands(content string, sourceOutput string) string {
	result := content

	// Patterns to replace with source output (captures indentation)
	patterns := []*regexp.Regexp{
		// source <(command)
		regexp.MustCompile(`(?m)^(\s*)source\s+<\([^)]+\)\s*$`),
		// . <(command)
		regexp.MustCompile(`(?m)^(\s*)\.\s+<\([^)]+\)\s*$`),
		// eval "$(command)" or eval "$(...)"
		regexp.MustCompile(`(?m)^(\s*)eval\s+"\$\([^)]+\)"\s*$`),
	}

	// Replace first match with source output, preserving indentation
	for _, pattern := range patterns {
		if pattern.MatchString(result) {
			result = pattern.ReplaceAllStringFunc(result, func(match string) string {
				// Extract indentation
				submatch := pattern.FindStringSubmatch(match)
				indent := ""
				if len(submatch) > 1 {
					indent = submatch[1]
				}

				// Add comment and inject source output with indentation
				lines := strings.Split(strings.TrimRight(sourceOutput, "\n"), "\n")
				indentedOutput := make([]string, len(lines))
				for i, line := range lines {
					if line != "" {
						indentedOutput[i] = indent + line
					} else {
						indentedOutput[i] = ""
					}
				}

				return fmt.Sprintf("%s# Cached from .source.sh:\n%s", indent, strings.Join(indentedOutput, "\n"))
			})
			break // Only replace one command
		}
	}

	return result
}

// replaceCommandsWithOutputs replaces command invocations with their cached outputs
func replaceCommandsWithOutputs(content string, commandMap map[string]string) string {
	result := content

	for _, pattern := range commandPatterns {
		result = pattern.ReplaceAllStringFunc(result, func(match string) string {
			// Extract command from match
			submatch := pattern.FindStringSubmatch(match)
			if len(submatch) < 2 {
				return match
			}

			cmd := strings.TrimSpace(submatch[1])
			output, exists := commandMap[cmd]

			if !exists || output == "" {
				// Keep original if command wasn't executed or had no output
				return match
			}

			// Check if command binary exists
			cmdParts := strings.Fields(cmd)
			if len(cmdParts) > 0 {
				if _, err := exec.LookPath(cmdParts[0]); err != nil {
					// Keep original if command doesn't exist
					return match
				}
			}

			// Replace with inline output
			// Add comment for clarity
			replacement := fmt.Sprintf("# Cached output of: %s\n%s", cmd, output)

			// If output doesn't end with newline, add one
			if !strings.HasSuffix(replacement, "\n") {
				replacement += "\n"
			}

			return replacement
		})
	}

	return result
}
